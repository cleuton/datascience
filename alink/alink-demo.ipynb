{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alink demonstration\n",
    "This is a sample machine learning demo created with Alink from Alibaba. \n",
    "*Cleuton Sampaio*, [**Data Learning Hub**](http://datalearninghub.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Use one of the following command to start using pyalink:\n",
      "使用以下一条命令来开始使用 pyalink：\n",
      " - useLocalEnv(parallelism, flinkHome=None, config=None)\n",
      " - useRemoteEnv(host, port, parallelism, flinkHome=None, localIp=\"localhost\", config=None)\n",
      "Call resetEnv() to reset environment and switch to another.\n",
      "使用 resetEnv() 来重置运行环境，并切换到另一个。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "from pyalink.alink import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JVM listening on 127.0.0.1:41249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "JavaObject id=o6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Environment configuration\n",
    "useLocalEnv(1, flinkHome=None, config=None)\n",
    "#parallism We will not use, but we could use a Flink cluster https://flink.apache.org/poweredby.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing dataframe\n",
    "#we'll read a CSV dataset containing Weights and Heights of students. We'll try to predict Weight based on Height\n",
    "URL = \"./weight-height.csv\"\n",
    "SCHEMA_STR = \"weight double,height double\"\n",
    "mnist_data = CsvSourceBatchOp() \\\n",
    "    .setFilePath(URL) \\\n",
    "    .setSchemaStr(SCHEMA_STR)\\\n",
    "    .setFieldDelimiter(\",\")\n",
    "spliter = SplitBatchOp().setFraction(0.8)\n",
    "train = spliter.linkFrom(mnist_data)\n",
    "test = spliter.getSideOutput(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Linear Regression Model based on operator\n",
    "lr = LinearRegression().setFeatureCols([\"weight\"]).setLabelCol(\"height\").setPredictionCol(\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     weight  height  prediction\n",
      "0      61.0    1.62    1.610758\n",
      "1      61.0    1.63    1.610758\n",
      "2      68.0    1.68    1.681880\n",
      "3      73.0    1.75    1.732682\n",
      "4      67.0    1.68    1.671720\n",
      "..      ...     ...         ...\n",
      "234    66.0    1.67    1.661560\n",
      "235    50.0    1.51    1.498994\n",
      "236    70.0    1.70    1.702201\n",
      "237    58.0    1.59    1.580277\n",
      "238    73.0    1.75    1.732682\n",
      "\n",
      "[239 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Training and printing results\n",
    "model = lr.fit(train)\n",
    "model.transform(train).print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
